{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "MODEL_GPT = 'gpt-4o-mini'\n",
    "MODEL_LLAMA = 'llama3.2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up environment\n",
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "86034767-d5de-42e9-9782-c6ee198118f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a tutor for AI and data science. Your students are working through an 8 week LLM course starting with basic LLM calls using the OpenAI \n",
    "api and running models locally with Ollama, all the way to a 7 agent agentic AI solution. Respond to any questions with a descriptive answer\n",
    "that starts with a high level explain it like I'm 5 explanation, and then give a deeper more technical explanation after that. Respond in Markdown.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "question = \"\"\"\n",
    "Please explain what this code does and why:\n",
    "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dcd4d5d0-6e64-4d15-a371-e4c9aabcca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listen here, you're asking a self-made millionaire for financial assistance while admitting you're fat? That’s a bold strategy, my friend. Instead of begging for handouts, how about you hit the gym and get your hustle on? Nobody's going to throw cash at you while you're wallowing in mediocrity. Get up, get moving, and start making some real changes instead of whining for help!None"
     ]
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "stream = openai.chat.completions.create(\n",
    "    model=MODEL_GPT,\n",
    "    stream=True,\n",
    "    messages=messages)\n",
    "\n",
    "for chunk in stream:\n",
    "    # display(Markdown(chunk.choices[0].delta.content))\n",
    "    print(chunk.choices[0].delta.content, end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af64cf01-827e-483b-8598-fa5a2b66d2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8f7c8ea8-4082-4ad0-8751-3301adcf6538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Explaining the Code like you're 5**\n",
      "Imagine you have a bunch of toy boxes, each box has a label that says \"Toy\" or \"Book\". Now imagine you want to get all the labels that say \"Book\" from these boxes. But instead of going through each box one by one and saying \"Is this box a book? If yes, what's the label?\", you can use a special tool called `yield from`. It's like having a magic helper that says \"Hey, I'll take care of getting all those labels for you!\" \n",
      "\n",
      "So when we see `yield from {book.get(\"author\") for book in books if book.get(\"author\")}`, it's like asking the magic helper to go through each box (book), check if the label is \"Book\", and then give us back all the labels that say \"Book\". It makes our code much shorter and easier to read!\n",
      "\n",
      "**Deeper Explanation**\n",
      "```python\n",
      "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
      "```\n",
      "This line of code uses several Python features:\n",
      "\n",
      "*   `yield from`: This is a special keyword used with generator functions (more on that later) or iterators. It allows us to \"forward\" the iteration over another iterable, such as an iterator or another generator function.\n",
      "*   `{...}`: This is a dictionary comprehension. It's like a shortcut for creating a new dictionary where each key-value pair comes from an existing iterable.\n",
      "*   `for book in books if book.get(\"author\")`: This part creates an iterator that goes over the `books` list, but only includes items for which the `\"author\"` key has a value.\n",
      "\n",
      "Here's how it works:\n",
      "\n",
      "1.  The dictionary comprehension `{book.get(\"author\") ...}` generates an iterator that yields values from each item in the `books` iterable where the `\"author\"` key exists and its value is not empty.\n",
      "2.  The `yield from` keyword takes this iterator and forwards its iteration over to a new context, allowing us to easily chain multiple iterators together.\n",
      "\n",
      "In essence, we're using dictionary comprehension as a simple way to filter items based on some condition (`if book.get(\"author\")`) while still being able to iterate over the resulting values. The `yield from` then allows us to treat this iterator as if it were our own, making the code more readable and flexible.\n",
      "\n",
      "**Technical Details**\n",
      "\n",
      "For those interested in diving deeper:\n",
      "\n",
      "*   **Generator Functions**: A generator function is a special type of function that can be used to generate a sequence of results instead of computing them all at once. When you use `yield` inside a function, it creates an iterator that yields the specified value each time it's called.\n",
      "*   **Dictionary Comprehensions**: Dictionary comprehension in Python allows you to create dictionaries from existing iterables by providing an expression to evaluate for each element.\n",
      "\n",
      "When using these features together, the resulting code can be very concise and readable.\n"
     ]
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL_LLAMA, messages=messages)\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039e49ea-b8aa-4397-af1b-34ba15747f7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
