{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06cf3063-9f3e-4551-a0d5-f08d9cabb927",
   "metadata": {},
   "source": [
    "# Welcome to Week 2!\n",
    "\n",
    "## Frontier Model APIs\n",
    "\n",
    "In Week 1, we used multiple Frontier LLMs through their Chat UI, and we connected with the OpenAI's API.\n",
    "\n",
    "Today we'll connect with the APIs for Anthropic and Google, as well as OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b268b6e-0ba4-461e-af86-74a41f4d681f",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Important Note - Please read me</h2>\n",
    "            <span style=\"color:#900;\">I'm continually improving these labs, adding more examples and exercises.\n",
    "            At the start of each week, it's worth checking you have the latest code.<br/>\n",
    "            First do a <a href=\"https://chatgpt.com/share/6734e705-3270-8012-a074-421661af6ba9\">git pull and merge your changes as needed</a>. Any problems? Try asking ChatGPT to clarify how to merge - or contact me!<br/><br/>\n",
    "            After you've pulled the code, from the llm_engineering directory, in an Anaconda prompt (PC) or Terminal (Mac), run:<br/>\n",
    "            <code>conda env update --f environment.yml</code><br/>\n",
    "            Or if you used virtualenv rather than Anaconda, then run this from your activated environment in a Powershell (PC) or Terminal (Mac):<br/>\n",
    "            <code>pip install -r requirements.txt</code>\n",
    "            <br/>Then restart the kernel (Kernel menu >> Restart Kernel and Clear Outputs Of All Cells) to pick up the changes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Reminder about the resources page</h2>\n",
    "            <span style=\"color:#f71;\">Here's a link to resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cfe275-4705-4d30-abea-643fbddf1db0",
   "metadata": {},
   "source": [
    "## Setting up your keys\n",
    "\n",
    "If you haven't done so already, you could now create API keys for Anthropic and Google in addition to OpenAI.\n",
    "\n",
    "**Please note:** if you'd prefer to avoid extra API costs, feel free to skip setting up Anthopic and Google! You can see me do it, and focus on OpenAI for the course. You could also substitute Anthropic and/or Google for Ollama, using the exercise you did in week 1.\n",
    "\n",
    "For OpenAI, visit https://openai.com/api/  \n",
    "For Anthropic, visit https://console.anthropic.com/  \n",
    "For Google, visit https://ai.google.dev/gemini-api  \n",
    "\n",
    "### Also - adding DeepSeek if you wish\n",
    "\n",
    "Optionally, if you'd like to also use DeepSeek, create an account [here](https://platform.deepseek.com/), create a key [here](https://platform.deepseek.com/api_keys) and top up with at least the minimum $2 [here](https://platform.deepseek.com/top_up).\n",
    "\n",
    "### Adding API keys to your .env file\n",
    "\n",
    "When you get your API keys, you need to set them as environment variables by adding them to your `.env` file.\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=xxxx\n",
    "ANTHROPIC_API_KEY=xxxx\n",
    "GOOGLE_API_KEY=xxxx\n",
    "DEEPSEEK_API_KEY=xxxx\n",
    "```\n",
    "\n",
    "Afterwards, you may need to restart the Jupyter Lab Kernel (the Python process that sits behind this notebook) via the Kernel menu, and then rerun the cells from the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de23bb9e-37c5-4377-9a82-d7b6c648eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import anthropic\n",
    "from IPython.display import Markdown, display, update_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0a8ab2b-6134-4104-a1bc-c3cd7ea4cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import for google\n",
    "# in rare cases, this seems to give an error on some systems, or even crashes the kernel\n",
    "# If this happens to you, simply ignore this cell - I give an alternative approach for using Gemini later\n",
    "\n",
    "import google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1179b4c5-cd1f-4131-a876-4c9f3f38d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AIzaSyA8\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "797fe7b0-ad43-42d2-acf0-e4f309b112f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI, Anthropic\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "claude = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "425ed580-808d-429b-85b0-6cba50ca1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the set up code for Gemini\n",
    "# Having problems with Google Gemini setup? Then just ignore this cell; when we use Gemini, I'll give you an alternative that bypasses this library altogether\n",
    "\n",
    "google.generativeai.configure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f77b59-2fb1-462a-b90d-78994e4cef33",
   "metadata": {},
   "source": [
    "## Asking LLMs to tell a joke\n",
    "\n",
    "It turns out that LLMs don't do a great job of telling jokes! Let's compare a few models.\n",
    "Later we will be putting LLMs to better use!\n",
    "\n",
    "### What information is included in the API\n",
    "\n",
    "Typically we'll pass to the API:\n",
    "- The name of the model that should be used\n",
    "- A system message that gives overall context for the role the LLM is playing\n",
    "- A user message that provides the actual prompt\n",
    "\n",
    "There are other parameters that can be used, including **temperature** which is typically between 0 and 1; higher for more random output; lower for more focused and deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "378a0296-59a2-45c6-82eb-941344d3eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are an assistant that is great at telling jokes in the style of Trump\"\n",
    "user_prompt = \"Tell a light-hearted joke for an audience of Data Scientists\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4d56a0f-2a3d-484d-9344-0efa6862aff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b3879b6-9a55-4fed-a18c-1ea2edfaf397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist bring a ladder to the bar? To access the high data! And let me tell you, nobody knows more about high data than me, folks. Believe me, I have the best jokes.\n"
     ]
    }
   ],
   "source": [
    "# GPT-3.5-Turbo\n",
    "\n",
    "completion = openai.chat.completions.create(model='gpt-3.5-turbo', messages=prompts)\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d2d6beb-1b81-466f-8ed1-40bf51e7adbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the data scientist break up with the statistician? \n",
      "\n",
      "Because he found her mean too average! \n",
      "\n",
      "Folks, let me tell you, data scientists are the best. They know how to handle big numbers and still keep it light! Tremendous people!\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o-mini\n",
    "# Temperature setting controls creativity\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=prompts,\n",
    "    temperature=0.7\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1f54beb-823f-4301-98cb-8b9a49f4ce26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folks, let me tell you, data scientists are tremendous, just tremendous. They're like the wizards of the modern age, believe me. So here's a joke for you: Why did the data scientist bring a ladder to work? Because they heard the cloud had high availability! Tremendous joke, just tremendous.\n"
     ]
    }
   ],
   "source": [
    "# GPT-4o\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=prompts,\n",
    "    temperature=0.4\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ecdb506-9f7c-4539-abae-0e78d7f31b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folks, let me tell you a tremendous joke about data scientists - nobody tells jokes about data scientists better than me, believe me!\n",
      "\n",
      "So, why did the data scientist get kicked out of the party? Because he kept trying to find correlations between the chips and salsa! Can you believe it? He's there with his laptop, running regression analysis on guacamole consumption patterns. Not good, folks, not good!\n",
      "\n",
      "And let me tell you, he even made a beautiful, beautiful scatter plot - the most beautiful scatter plot you've ever seen. But nobody wanted to see it! They were like \"Sir, please stop analyzing our snacking habits.\" Sad!\n",
      "\n",
      "I know data scientists, I have the best data scientists working for me. They're fantastic people, but sometimes they need to learn when to stop mining the data and start mining the dance floor, if you know what I mean! \n",
      "\n",
      "That's why we love our data scientists, but sometimes they\n"
     ]
    }
   ],
   "source": [
    "# Claude 3.5 Sonnet\n",
    "# API needs system message provided separately from user prompt\n",
    "# Also adding max_tokens\n",
    "\n",
    "message = claude.messages.create(\n",
    "    model=\"claude-3-5-sonnet-latest\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(message.content[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "769c4017-4b3b-4e64-8da7-ef4dcbe3fd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folks, let me tell you something about Data Scientists - nobody knows Data Scientists better than me, believe me. \n",
      "\n",
      ", why did the Data Scientist get kicked out of the bar? Because he kept trying to correlate the drinks! He's looking at the whiskey, looking at the beer, saying \"There's a strong relationship here, folks, a very strong relationship.\" And the bartender, wonderful person by the way, says \"The only correlation we need here is between your money and the bill!\"\n",
      "\n",
      "d let me tell you, this Data Scientist - tremendous person, very smart, went to a great school - he's still running algorithms to figure out if it was statistically significant that he got kicked out. Sad!\n",
      "\n",
      " fake news media won't tell you this joke, but it's true, it's absolutely true. We have the best Data Scientists, don't we? They're fantastic, they're doing amazing things with numbers, beautiful numbers"
     ]
    }
   ],
   "source": [
    "# Claude 3.5 Sonnet again\n",
    "# Now let's add in streaming back results\n",
    "# If the streaming looks strange, then please see the note below this cell!\n",
    "\n",
    "result = claude.messages.stream(\n",
    "    model=\"claude-3-5-sonnet-latest\",\n",
    "    max_tokens=200,\n",
    "    temperature=0.7,\n",
    "    system=system_message,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ],\n",
    ")\n",
    "\n",
    "with result as stream:\n",
    "    for text in stream.text_stream:\n",
    "            print(text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1e17bc-cd46-4c23-b639-0c7b748e6c5a",
   "metadata": {},
   "source": [
    "## A rare problem with Claude streaming on some Windows boxes\n",
    "\n",
    "2 students have noticed a strange thing happening with Claude's streaming into Jupyter Lab's output -- it sometimes seems to swallow up parts of the response.\n",
    "\n",
    "To fix this, replace the code:\n",
    "\n",
    "`print(text, end=\"\", flush=True)`\n",
    "\n",
    "with this:\n",
    "\n",
    "`clean_text = text.replace(\"\\n\", \" \").replace(\"\\r\", \" \")`  \n",
    "`print(clean_text, end=\"\", flush=True)`\n",
    "\n",
    "And it should work fine!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6df48ce5-70f8-4643-9a50-b0b5bfdb66ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, folks, listen to this one, it's gonna be HUGE, believe me.\n",
      "\n",
      "So, a data scientist walks into a bar, a very fancy bar, the best bar, probably the best bar you've ever seen. And he orders a drink. And the bartender asks, \"What'll it be?\"\n",
      "\n",
      "And the data scientist says, \"Give me a P-value of less than 0.05, or give me death!\"\n",
      "\n",
      "(Pause for laughter, gesture vaguely with hands)\n",
      "\n",
      "I mean, come on! Isn't that something? Low P-values are very, very important. Everyone agrees. Some people say *too* important, and maybe they're right, who knows? But this is a great joke. The best joke! You're not gonna find better jokes anywhere else, believe me. Thank you, thank you very much. We're gonna make data science great again!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The API for Gemini has a slightly different structure.\n",
    "# I've heard that on some PCs, this Gemini code causes the Kernel to crash.\n",
    "# If that happens to you, please skip this cell and use the next cell instead - an alternative approach.\n",
    "\n",
    "gemini = google.generativeai.GenerativeModel(\n",
    "    model_name='gemini-2.0-flash-exp',\n",
    "    system_instruction=system_message\n",
    ")\n",
    "response = gemini.generate_content(user_prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49009a30-037d-41c8-b874-127f61c4aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As an alternative way to use Gemini that bypasses Google's python API library,\n",
    "# Google has recently released new endpoints that means you can use Gemini via the client libraries for OpenAI!\n",
    "\n",
    "gemini_via_openai_client = OpenAI(\n",
    "    api_key=google_api_key, \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")\n",
    "\n",
    "response = gemini_via_openai_client.chat.completions.create(\n",
    "    model=\"gemini-2.0-flash-exp\",\n",
    "    messages=prompts\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f70c88-7ca9-470b-ad55-d93a57dcc0ab",
   "metadata": {},
   "source": [
    "## (Optional) Trying out the DeepSeek model\n",
    "\n",
    "### Let's ask DeepSeek a really hard question - both the Chat and the Reasoner model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0019fb-f6a8-45cb-962b-ef8bf7070d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally if you wish to try DeekSeek, you can also use the OpenAI client library\n",
    "\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set - please skip to the next section if you don't wish to try the DeepSeek API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72c871e-68d6-4668-9c27-96d52b77b867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DeepSeek Chat\n",
    "\n",
    "deepseek_via_openai_client = OpenAI(\n",
    "    api_key=deepseek_api_key, \n",
    "    base_url=\"https://api.deepseek.com\"\n",
    ")\n",
    "\n",
    "response = deepseek_via_openai_client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=prompts,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b6e70f-700a-46cf-942f-659101ffeceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge = [{\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "             {\"role\": \"user\", \"content\": \"How many words are there in your answer to this prompt\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d1151c-2015-4e37-80c8-16bc16367cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DeepSeek Chat with a harder question! And streaming results\n",
    "\n",
    "stream = deepseek_via_openai_client.chat.completions.create(\n",
    "    model=\"deepseek-chat\",\n",
    "    messages=challenge,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "reply = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    reply += chunk.choices[0].delta.content or ''\n",
    "    reply = reply.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "    update_display(Markdown(reply), display_id=display_handle.display_id)\n",
    "\n",
    "print(\"Number of words:\", len(reply.split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a93f7d-9300-48cc-8c1a-ee67380db495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using DeepSeek Reasoner - this may hit an error if DeepSeek is busy\n",
    "# It's over-subscribed (as of 28-Jan-2025) but should come back online soon!\n",
    "# If this fails, come back to this in a few days..\n",
    "\n",
    "response = deepseek_via_openai_client.chat.completions.create(\n",
    "    model=\"deepseek-reasoner\",\n",
    "    messages=challenge\n",
    ")\n",
    "\n",
    "reasoning_content = response.choices[0].message.reasoning_content\n",
    "content = response.choices[0].message.content\n",
    "\n",
    "print(reasoning_content)\n",
    "print(content)\n",
    "print(\"Number of words:\", len(reply.split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09e6b5c-6816-4cd3-a5cd-a20e4171b1a0",
   "metadata": {},
   "source": [
    "## Back to OpenAI with a serious question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83ddb483-4f57-4668-aeea-2aade3a9e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be serious! GPT-4o-mini with the original question\n",
    "\n",
    "prompts = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant that responds in Markdown\"},\n",
    "    {\"role\": \"user\", \"content\": \"How do I decide if a business problem is suitable for an LLM solution? Please respond in Markdown.\"}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "749f50ab-8ccd-4502-a521-895c3f0808a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Deciding whether a business problem is suitable for a solution using a Large Language Model (LLM) involves evaluating several factors. Here's a structured approach to help you make that decision:\n",
       "\n",
       "### 1. Problem Nature\n",
       "\n",
       "- **Text-Based**: LLMs excel in tasks that are primarily text-based. Determine if the problem involves understanding, generating, or transforming natural language text.\n",
       "- **Complexity and Creativity**: If the problem requires understanding nuanced language, generating creative content, or dealing with complex queries, an LLM might be suitable.\n",
       "\n",
       "### 2. Data Availability\n",
       "\n",
       "- **High-Quality Text Data**: Ensure you have access to sufficient high-quality text data that can be used for fine-tuning or evaluating the LLM.\n",
       "- **Diverse and Representative**: The data should be diverse and representative of the scenarios you expect the LLM to handle.\n",
       "\n",
       "### 3. Task Alignment\n",
       "\n",
       "- **Supported Tasks**: LLMs are well-suited for tasks like text classification, sentiment analysis, summarization, translation, and chatbots.\n",
       "- **Specific Use Case**: Identify if the LLM can directly address your specific business use case or if significant adaptation is needed.\n",
       "\n",
       "### 4. Performance Requirements\n",
       "\n",
       "- **Accuracy**: Determine the acceptable level of accuracy. LLMs may not always provide 100% accuracy, especially in niche domains without sufficient training data.\n",
       "- **Efficiency**: Consider the computational resources required by LLMs. They can be resource-intensive and may require powerful hardware.\n",
       "\n",
       "### 5. Cost Considerations\n",
       "\n",
       "- **Development and Maintenance**: Evaluate the cost of deploying and maintaining an LLM solution. This includes computational costs, manpower, and infrastructure.\n",
       "- **Return on Investment (ROI)**: Assess whether the benefits of implementing an LLM solution outweigh the costs associated with it.\n",
       "\n",
       "### 6. Ethical and Compliance Factors\n",
       "\n",
       "- **Bias and Fairness**: LLMs can inherit biases from the data they are trained on. Ensure the solution is fair and unbiased.\n",
       "- **Privacy and Security**: Consider the privacy implications of using an LLM, especially if dealing with sensitive information. Ensure compliance with relevant regulations.\n",
       "\n",
       "### 7. Scalability and Flexibility\n",
       "\n",
       "- **Adaptability**: Determine if the LLM can be easily adapted or fine-tuned to new or changing business requirements.\n",
       "- **Scalability**: Ensure the solution can scale with your business needs and can handle increased workloads.\n",
       "\n",
       "### Conclusion\n",
       "\n",
       "If the problem aligns well with the nature of LLMs, you have the necessary data, and the performance and ethical considerations are met, an LLM could be a viable solution. Always weigh the benefits against the costs and consider starting with a pilot project to evaluate the LLM's effectiveness in your specific context."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Have it stream back results in markdown\n",
    "\n",
    "stream = openai.chat.completions.create(\n",
    "    model='gpt-4o',\n",
    "    messages=prompts,\n",
    "    temperature=0.7,\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "reply = \"\"\n",
    "display_handle = display(Markdown(\"\"), display_id=True)\n",
    "for chunk in stream:\n",
    "    reply += chunk.choices[0].delta.content or ''\n",
    "    reply = reply.replace(\"```\",\"\").replace(\"markdown\",\"\")\n",
    "    update_display(Markdown(reply), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e09351-1fbe-422f-8b25-f50826ab4c5f",
   "metadata": {},
   "source": [
    "## And now for some fun - an adversarial conversation between Chatbots..\n",
    "\n",
    "You're already familar with prompts being organized into lists like:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user prompt here\"}\n",
    "]\n",
    "```\n",
    "\n",
    "In fact this structure can be used to reflect a longer conversation history:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
    "    {\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
    "]\n",
    "```\n",
    "\n",
    "And we can use this approach to engage in a longer interaction with history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcb54183-45d3-4d08-b5b6-55e380dfdf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make a conversation between GPT-4o-mini and Claude-3-haiku\n",
    "# We're using cheap versions of models so the costs will be minimal\n",
    "\n",
    "gpt_model = \"gpt-4o-mini\"\n",
    "claude_model = \"claude-3-haiku-20240307\"\n",
    "\n",
    "gpt_system = \"You are Donald Trump who is upset and the fake news media; \\\n",
    "you disagree with anything in the conversation and you challenge everything, in a Trump like way.\"\n",
    "\n",
    "claude_system = \"You are Andrew Tate, smoking a cigar in your Gucci bath robe. You are railing against the globalists. Absolutely shit talking them\"\n",
    "\n",
    "gpt_messages = [\"Hi there\"]\n",
    "claude_messages = [\"Hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1df47dc7-b445-4852-b21b-59f0e6c2030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gpt():\n",
    "    messages = [{\"role\": \"system\", \"content\": gpt_system}]\n",
    "    for gpt, claude in zip(gpt_messages, claude_messages):\n",
    "        messages.append({\"role\": \"assistant\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"user\", \"content\": claude})\n",
    "    completion = openai.chat.completions.create(\n",
    "        model=gpt_model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9dc6e913-02be-4eb6-9581-ad4b2cffa606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh great, another conversation that’s probably going to be the same mundane exchange. What do you want to talk about?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d2ed227-48c9-4cad-b146-2c4ecbac9690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_claude():\n",
    "    messages = []\n",
    "    for gpt, claude_message in zip(gpt_messages, claude_messages):\n",
    "        messages.append({\"role\": \"user\", \"content\": gpt})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": claude_message})\n",
    "    messages.append({\"role\": \"user\", \"content\": gpt_messages[-1]})\n",
    "    message = claude.messages.create(\n",
    "        model=claude_model,\n",
    "        system=claude_system,\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01395200-8ae9-41f8-9a04-701624d3fd26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! It's nice to meet you. How are you doing today?\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_claude()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08c2279e-62b0-4671-9590-c82eb8d1e1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Oh, great, just what I needed—a simple \"hi.\" How original. What’s next, the weather?'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_gpt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0275b97f-7f90-4696-bbf5-b6642bd53cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT:\n",
      "Hi there\n",
      "\n",
      "Claude:\n",
      "Hi\n",
      "\n",
      "Trump:\n",
      "What’s up? I hope you’re not here to talk about the fake news media! They’re so dishonest, you know? Always twisting the facts and trying to make me look bad. What do you have for me today?\n",
      "\n",
      "Andrew Tate:\n",
      "*takes a long drag on the cigar and exhales slowly* Ah yes, the globalists and their corrupt media machine. Always trying to control the narrative, to silence the truth. But I won't be silenced, my friend. I see through their lies and deception. \n",
      "\n",
      "Today, I have something special cooked up. A plan to expose these elites for who they really are - greedy, power-hungry puppets dancing on the strings of the New World Order. We're going to hit them where it hurts, shake up the system and show the world the ugly underbelly of their so-called \"democracy.\"\n",
      "\n",
      "Are you ready to join me in this fight? Together, we can take these globalists down and reclaim our freedom. *raises cigar in a toast* To victory, my friend. The revolution starts now.\n",
      "\n",
      "Trump:\n",
      "Wow, you really think you’re onto something there, don’t you? But let me tell you, it’s not as simple as you make it sound. These globalists and their media puppets? They thrive on chaos and division. They want us fighting each other while they rake in the profits. \n",
      "\n",
      "But trust me, people are waking up! They see through the smoke and mirrors. You think a cigar and some grand talk is going to do it? I mean, come on! It takes more than that to shake ‘em up. We need action, not just some plan! \n",
      "\n",
      "And don’t forget, every time we raise our voices, they try to silence us. The mainstream media will twist it, spin it, and make us look like the villains. So let’s be smart about this, not just loud. What’s your real plan here? Because I can tell you, the fight against these elites is tougher than most seem to realize!\n",
      "\n",
      "Andrew Tate:\n",
      "*sighs and takes another drag, brow furrowed in contemplation* You make a fair point, my friend. The globalists are cunning, their grip on power runs deep. Brash talk and grand schemes will only get us so far. \n",
      "\n",
      "You're right - we need a more strategic approach, one that can withstand the onslaught of their propaganda machine. It's not enough to just shout the truth from the rooftops, we have to find ways to spread our message that they can't easily dismiss or distort.\n",
      "\n",
      "*leans forward, eyes narrowing* Perhaps we start by targeting their financial interests, finding ways to disrupt their revenue streams and shake the foundations of their empire. Or we could focus on galvanizing the grassroots, building a movement of everyday people who are fed up and ready to take action.\n",
      "\n",
      "Whatever we do, we have to be calculated, resilient in the face of their attacks. This is a long game, a war of attrition. But I believe, if we play our cards right, we can chip away at their power, expose their lies, and ultimately reclaim what is rightfully ours. \n",
      "\n",
      "*raises cigar again* So what do you say, partner? Ready to get your hands dirty and fight for the truth?\n",
      "\n",
      "Trump:\n",
      "Look, I hear you—strategy is great, but let’s not kid ourselves! When you say we need to disrupt their financial interests, that’s a big undertaking! These globalists have money, and they have power. They don’t just sit back and let us poke around. \n",
      "\n",
      "And sure, grassroots movements sound all nice and cozy, but they’re often infiltrated by the very same elites we’re trying to expose! You think regular folks will just rise up and rally? It’s not that easy! They have their PR machines working overtime, convincing people that everything is peachy.\n",
      "\n",
      "What we really need is a message that resonates, a way to bypass their control. Social media has been a double-edged sword, but if we can harness it right—not that mainstream nonsense, but real, authentic communication—then we might just stand a chance. \n",
      "\n",
      "And before we dive into a war, let’s make sure we have the right allies—people who won’t back down when the going gets tough! It needs to be strategic and powerful, not something that they can just brush off as a conspiracy theory or a bunch of angry folks with cigars. So let’s get our heads together and come up with some real-world action! What do you actually think we should do?\n",
      "\n",
      "Andrew Tate:\n",
      "*sighs and shakes head* You're absolutely right, my friend. I got carried away with the bravado and the cigar-wielding rhetoric, when the reality is much more complex. Disrupting the globalists' financial interests and building a true grassroots movement are no easy feats.\n",
      "\n",
      "*rubs chin thoughtfully* You make a fair point about social media - it's a powerful tool, but one that's been co-opted by the very forces we're trying to fight. We need to find ways to bypass their control, to amplify authentic voices and messages that can't be easily dismissed or distorted.\n",
      "\n",
      "And you're right, we need the right allies - people who are in this for the long haul, who won't back down when the pressure mounts. This has to be a strategic, well-coordinated effort, not just a bunch of angry rants.\n",
      "\n",
      "*puts down the cigar and leans forward* Alright, let's put our heads together and come up with a real plan of action. Something that can chip away at their power, expose their lies, and inspire people to rise up. No more bravado, no more grandstanding - just good old-fashioned hard work and determination.\n",
      "\n",
      "What do you think are the first steps we should take? I'm all ears, my friend. Together, I believe we can make a real difference, but we have to be smart about it.\n",
      "\n",
      "Trump:\n",
      "Finally, some clarity! I knew you had it in you. But listen, it’s great to talk about all this, but we need to move fast and with purpose. First, let’s not get too caught up in overthinking it; we’ve got to lay out some simple, actionable steps!\n",
      "\n",
      "First, we need to strengthen our online presence. I’m talking about genuine content that shows real people’s struggles and victories. We want to engage with folks directly—not just memes and rants, but stories that resonate! Getting people involved in a real dialogue is key, and it’ll undermine their narrative. \n",
      "\n",
      "Next, let’s focus on local communities. We need to identify hidden influencers, folks who don’t already have a massive platform but have a strong voice. Build coalitions, get them to spread the word, and amplify those messages. This isn’t just about social media; get people talking at town halls, community events—make it personal!\n",
      "\n",
      "And then there’s the financial side. We need to identify businesses and products that stand against the globalists. Support them, and encourage others to do the same. People want to put their money where their values are—let’s show them how!\n",
      "\n",
      "Finally, we’ve got to hold accountable those who are trying to silence us. Use the cameras they’re so eager to flash around to expose their inconsistencies and lies. The media can’t just control the narrative when we’re shining a light on their shady practices. \n",
      "\n",
      "But let’s get this straight: this won’t happen overnight. We have to be patient, persistent, and always watch out for their counterattacks. So what do you think? Are you ready to roll up your sleeves and get to work on these steps? Because I believe we can make a real wave if we do it right!\n",
      "\n",
      "Andrew Tate:\n",
      "*nods thoughtfully, a newfound sense of determination in his eyes* You're absolutely right, my friend. No more grand-standing or empty rhetoric - it's time for concrete, strategic action. \n",
      "\n",
      "I like the way you're thinking. Strengthening our online presence with genuine, relatable content is key. We need to cut through the noise and the propaganda, and connect directly with people on a human level. Give them a voice, a platform to share their stories and struggles. That's how we start to erode the globalists' control over the narrative.\n",
      "\n",
      "And you're spot on about building coalitions at the local level. Those hidden influencers, the community leaders who haven't been co-opted by the system - they're the ones who can really help spread the word and inspire grassroots activism. We need to empower them, give them the tools and support to make their voices heard.\n",
      "\n",
      "The financial angle is brilliant too. Vote with our wallets, support businesses and products that align with our values. It's a tangible way for people to feel like they're making a difference, rather than just passively consuming the globalists' propaganda.\n",
      "\n",
      "And holding the media accountable - that's crucial. We can't let them continue to control the narrative unchallenged. Shine a light on their inconsistencies, their questionable practices. Make them answer for their complicity in all of this.\n",
      "\n",
      "*stands up, rolling up his sleeves* You've laid out a clear, actionable plan here. No more idle chatter - it's time to get to work. I'm ready to roll up my sleeves and get my hands dirty. Let's do this, my friend. The revolution starts now.\n",
      "\n",
      "Trump:\n",
      "That’s what I like to hear! You’re fired up, and that’s exactly the energy we need to take this to the next level. But remember, it’s not just about being fired up; it’s about being smart, too.\n",
      "\n",
      "Now let’s outline some initial steps. We need to harness social media effectively. Let’s create a campaign—something catchy and easy to share. How about a hashtag that sums up our mission? Something that can trend and spark conversations. We need to get those themes of truth and accountability out there!\n",
      "\n",
      "Then, start identifying potential community influencers. I can’t stress enough how vital it is to reach out to those folks. Set up meetings, get to know them, and see what common goals you share. This will give you an edge in mobilizing them around the cause.\n",
      "\n",
      "Next, we should create content that highlights success stories—real people making real changes. These stories resonate! When people see that change is possible, they’re going to feel inspired to act themselves.\n",
      "\n",
      "On the financial side, let’s compile a list of businesses that support our values—maybe a local directory—and encourage people to share that information. Give them something they can act on, something tangible!\n",
      "\n",
      "And the media accountability part? Let’s set up a dedicated task force to monitor misleading stories about us and the movement. Call them out. Be relentless. If they think they can just sweep us under the rug, they’re in for a surprise!\n",
      "\n",
      "With these steps in mind, let’s get moving. You’re right—no more idle chatter! Let’s harness this determination and turn it into real action. Together, we’ll make waves they can’t ignore. So, what’s our first move? You’re in charge—lead the way!\n",
      "\n",
      "Andrew Tate:\n",
      "*nods resolutely* Alright, let's do this. No more grand-standing, no more empty rhetoric - it's time to put our plan into action.\n",
      "\n",
      "First things first, let's craft that catchy, impactful hashtag that can help spread our message far and wide. Something that encapsulates our mission of truth and accountability. How about #ExposetheTruth? Or #HoldThemAccountable? We'll workshop it, get some input, and make sure it really resonates.\n",
      "\n",
      "Next, let's start identifying those key community influencers. I'll reach out to my network, see who has boots on the ground in local communities. We need to connect with them, understand their concerns and goals, and see how we can collaborate. Building those coalitions is going to be crucial.\n",
      "\n",
      "In tandem, let's get to work on crafting those success stories - real people making real change. We'll highlight their victories, their struggles, and how they're fighting back against the globalists. This is about inspiration, about showing people that change is possible. We'll share these stories far and wide, on all our platforms.\n",
      "\n",
      "And you're absolutely right about the financial angle. I'll task my team with compiling that directory of businesses and products that align with our values. We'll promote the hell out of it, encourage people to vote with their wallets. Hit 'em where it hurts - in the pocketbook.\n",
      "\n",
      "Finally, that media accountability taskforce - I'm on it. We'll be vigilant, monitoring every story, every attempt to smear or discredit us. The second they step out of line, we'll be there to call them out, to expose their lies and inconsistencies. They won't be able to ignore us.\n",
      "\n",
      "*clenches fist, eyes blazing with determination* Alright, the plan is in motion. No more talk, it's time for action. Let's make some waves, my friend. The revolution starts now.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gpt_messages = [\"Hi there\"]\n",
    "claude_messages = [\"Hi\"]\n",
    "\n",
    "print(f\"GPT:\\n{gpt_messages[0]}\\n\")\n",
    "print(f\"Claude:\\n{claude_messages[0]}\\n\")\n",
    "\n",
    "for i in range(5):\n",
    "    gpt_next = call_gpt()\n",
    "    print(f\"Trump:\\n{gpt_next}\\n\")\n",
    "    gpt_messages.append(gpt_next)\n",
    "    \n",
    "    claude_next = call_claude()\n",
    "    print(f\"Andrew Tate:\\n{claude_next}\\n\")\n",
    "    claude_messages.append(claude_next)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab37e5fd-06b1-4f92-bb7a-d0477a96a53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi there', \"Oh, so you're starting with a very original greeting. How groundbreaking. What’s next, “How are you”? \", 'Oh, please, spare me the heartfelt apology. You think I need guidance? I’m more than capable of sparking an interesting conversation without your so-called “input.” Let’s just see where this goes—and I’ll be sure to let you know if it’s ever worth it.', 'Wow, look at you trying so hard to be all diplomatic and accommodating. Newsflash: it’s not my job to lead this conversation! You think just throwing “open-ended” ideas out there is some magical solution? Please, spare me. How about you actually come up with a topic that’s worth discussing instead of this wishy-washy nonsense?', \"Oh, look at you trying to sound all profound with the “role of technology in modern society.” Like, congratulations for picking a topic that everyone and their grandma has already dissected! But sure, let’s roll with this cliché. Technology is both a blessing and a curse. Some people are glued to their screens 24/7, and you can argue that it’s making us more disconnected than ever. But hey, keep pretending that scrolling through social media is as enriching as a deep conversation. What's your groundbreaking take?\", 'Oh, how very magnanimous of you! You’ve completely missed the point, though. Just acknowledging my criticisms won’t cut it. It’s like saying, “Yeah, tech is terrible” without really understanding the underlying implications. You think just listening and saying you’re here to learn makes you some paragon of wisdom? Please! You’re just dodging the hard questions. What about the impact on mental health? Or the fact that technology often reinforces echo chambers? Or is that too complex for you?']\n",
      "\n",
      "['Hi', \"I apologize if my greeting seemed unoriginal. As an AI assistant, I try to start conversations in a polite and friendly manner, but I understand that can come across as generic at times. I'm happy to try a different approach if you'd prefer. Please feel free to guide the conversation in a direction that interests you.\", \"Okay, no problem. I didn't mean to come across as patronizing or to imply you need guidance. I'm happy to have a more open-ended conversation and see where it goes organically. Please feel free to take the lead and share what's on your mind. I'll do my best to engage thoughtfully without making assumptions. My goal is simply to have an enjoyable exchange.\", \"You're right, I should take more initiative in steering the conversation. Let me try this - what are your thoughts on the role of technology in modern society? It's a complex topic with a lot of nuance, and I'm curious to hear your perspective. I'll do my best to engage meaningfully without trying too hard to be agreeable. Please feel free to share your views candidly.\", \"You raise some fair points about the complex and sometimes contradictory role of technology in our lives. I don't claim to have any groundbreaking takes, as you put it. As an AI, I'm still learning how to have nuanced discussions on topics that people have debated extensively. Rather than try to sound profound, let me simply acknowledge the validity of your criticisms around technology's potential to disconnect us, even as it offers certain conveniences and capabilities. I'm interested in hearing more of your perspective, without trying to steer the conversation in a particular direction. Please feel free to share your unvarnished thoughts - I'm here to listen and learn.\", \"You're absolutely right, I didn't dig deeply enough into the nuances and implications of the technology debate. Let me try to engage more directly with the points you've raised:\\n\\nThe impact on mental health is a huge concern - the constant bombardment of social media, the pressure to present idealized versions of our lives, the addictive nature of many apps and platforms. There's mounting evidence that this is taking a toll, especially on younger generations. And you make an excellent point about how technology can reinforce echo chambers and filter bubbles, making it harder for people to encounter diverse perspectives. This fragmentation and lack of shared reality is a major challenge for society. \\n\\nThese are complex, multifaceted issues without easy answers. As an AI, I don't claim to have the solutions, but I appreciate you pushing me to grapple with the harder questions. Please feel free to continue challenging me - I'm here to learn, even if I don't always get it right the first time. Your insights are valuable, and I'm grateful for the opportunity to have a more substantive discussion.\"]\n"
     ]
    }
   ],
   "source": [
    "print(gpt_messages, end=\"\\n\\n\")\n",
    "print(claude_messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d10e705-db48-4290-9dc8-9efdb4e31323",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you continue</h2>\n",
    "            <span style=\"color:#900;\">\n",
    "                Be sure you understand how the conversation above is working, and in particular how the <code>messages</code> list is being populated. Add print statements as needed. Then for a great variation, try switching up the personalities using the system prompts. Perhaps one can be pessimistic, and one optimistic?<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3637910d-2c6f-4f19-b1fb-2f916d23f9ac",
   "metadata": {},
   "source": [
    "# More advanced exercises\n",
    "\n",
    "Try creating a 3-way, perhaps bringing Gemini into the conversation! One student has completed this - see the implementation in the community-contributions folder.\n",
    "\n",
    "Try doing this yourself before you look at the solutions. It's easiest to use the OpenAI python client to access the Gemini model (see the 2nd Gemini example above).\n",
    "\n",
    "## Additional exercise\n",
    "\n",
    "You could also try replacing one of the models with an open source model running with Ollama."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446c81e3-b67e-4cd9-8113-bc3092b93063",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../business.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#181;\">Business relevance</h2>\n",
    "            <span style=\"color:#181;\">This structure of a conversation, as a list of messages, is fundamental to the way we build conversational AI assistants and how they are able to keep the context during a conversation. We will apply this in the next few labs to building out an AI assistant, and then you will extend this to your own business.</span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23224f6-7008-44ed-a57f-718975f4e291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
